{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main_updated.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sE-d_RA5RRV3","executionInfo":{"status":"ok","timestamp":1642581786253,"user_tz":-330,"elapsed":23643,"user":{"displayName":"Aman Malhotra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjO8Kg9YRycERg3BHMe65bFSpgEE50QQIFUZ_UgeA=s64","userId":"15403737996651190546"}},"outputId":"aa5d3608-fa8a-4c09-994e-543f96207a34","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# import necessary libraries\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","import re\n","import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","sns.set(font_scale = 1.5)\n","sns.set_style('whitegrid')"]},{"cell_type":"code","source":["# purpose   : read data from *.sngval files into respective data blocks\n","def get_separated_data():  \n","  all_data_without_space = []\n","  all_data_separated = []\n","  for i in np.arange(len(file_data)):\n","    all_data_without_space.append(re.sub(r'\\(.*?\\)', lambda x: ''.join(x.group(0).split()), file_data[i]).strip())\n","  for i in np.arange(len(all_data_without_space)):\n","    sample_record = []\n","    splitted_data = all_data_without_space[i].split('  ')\n","    for j in np.arange(len(splitted_data)):\n","      if(splitted_data[j] == ''):\n","        continue\n","      else :\n","        sample_record.append(splitted_data[j])\n","    all_data_separated.append(sample_record)\n","  return all_data_separated\n","#-----------------------------------------------------------------------------\n","def get_data_in_dataframe(all_data_separated, max_length):\n","  i = 0\n","  while i < len(all_data_separated):\n","    if (not all_data_separated[i]):\n","      i = i + 1\n","      continue\n","    elif (all_data_separated[i][0] == '='*max_length):\n","      dict_1[all_data_separated[i+1][0]] = pd.DataFrame(columns = all_data_separated[i+3])\n","      index = i + 1 \n","      i = i+5\n","    else : \n","      df_name = all_data_separated[index][0]\n","      dict_1[df_name].loc[i-5] = all_data_separated[i]\n","      i = i+1\n","#-----------------------------------------------------------------------------\n","def remove_parenthesis_string(text):\n","  return text.replace(')','')\n","#-----------------------------------------------------------------------------\n","def clean_data():  \n","  dict_1['CURVE BASIC SUMMARY DATA'][['MINY','MINY_XVAL']] = dict_1['CURVE BASIC SUMMARY DATA']['MINY ->(XVAL)'].apply(lambda x : pd.Series(str(x).split('(')))\n","  dict_1['CURVE BASIC SUMMARY DATA'][['MAXY','MAXY_XVAL']] = dict_1['CURVE BASIC SUMMARY DATA']['MAXY ->(XVAL)'].apply(lambda x : pd.Series(str(x).split('(')))\n","  dict_1['CURVE BASIC SUMMARY DATA'][['LST_NONZ','LST_NONZ_YVAL']] = dict_1['CURVE BASIC SUMMARY DATA']['LST_NONZ ->(YVAL)'].apply(lambda x : pd.Series(str(x).split('(')))\n","  dict_1['CURVE BASIC SUMMARY DATA'].drop(['MINY ->(XVAL)','MAXY ->(XVAL)','LST_NONZ ->(YVAL)'], axis=1,inplace = True)\n","\n","  dict_1['CURVE BASIC SUMMARY DATA']['MINY_XVAL'] = dict_1['CURVE BASIC SUMMARY DATA']['MINY_XVAL'].apply(lambda x : remove_parenthesis_string(x))\n","  dict_1['CURVE BASIC SUMMARY DATA']['MAXY_XVAL'] = dict_1['CURVE BASIC SUMMARY DATA']['MAXY_XVAL'].apply(lambda x : remove_parenthesis_string(x))\n","  dict_1['CURVE BASIC SUMMARY DATA']['LST_NONZ_YVAL'] = dict_1['CURVE BASIC SUMMARY DATA']['LST_NONZ_YVAL'].apply(lambda x : remove_parenthesis_string(x))\n","\n","  dict_1['CURVE BASIC SUMMARY DATA'] = dict_1['CURVE BASIC SUMMARY DATA'].astype(np.float32)\n","  dict_1['CURVE INJURY SUMMARY DATA:'][['HIC','HIC_T1_T2']] = dict_1['CURVE INJURY SUMMARY DATA:']['HIC ----->(T1,T2)'].apply(lambda x : pd.Series(str(x).split('(')))\n","  dict_1['CURVE INJURY SUMMARY DATA:'][['HIC_T1','HIC_T2']] = dict_1['CURVE INJURY SUMMARY DATA:']['HIC_T1_T2'].apply(lambda x : pd.Series(str(x).split(',')))\n","  dict_1['CURVE INJURY SUMMARY DATA:'][['HICD','HICD_T1_T2']] = dict_1['CURVE INJURY SUMMARY DATA:']['HICD ----->(T1,T2)'].apply(lambda x : pd.Series(str(x).split('(')))\n","  dict_1['CURVE INJURY SUMMARY DATA:'][['HICD_T1','HICD_T2']] = dict_1['CURVE INJURY SUMMARY DATA:']['HICD_T1_T2'].apply(lambda x : pd.Series(str(x).split(',')))\n","  dict_1['CURVE INJURY SUMMARY DATA:'][['3MS','3MS_T1_T2']] = dict_1['CURVE INJURY SUMMARY DATA:'][' 3MS ----->(T1,T2)'].apply(lambda x : pd.Series(str(x).split('(')))\n","  dict_1['CURVE INJURY SUMMARY DATA:'][['3MS_T1','3MS_T2']] = dict_1['CURVE INJURY SUMMARY DATA:']['3MS_T1_T2'].apply(lambda x : pd.Series(str(x).split(',')))\n","  dict_1['CURVE INJURY SUMMARY DATA:'][['THIV', 'THIV_TIME']] = dict_1['CURVE INJURY SUMMARY DATA:']['THIV --->(Time)'].apply(lambda x : pd.Series(str(x).split('(')))\n","  dict_1['CURVE INJURY SUMMARY DATA:'][['PHD', 'PHD_TIME']] = dict_1['CURVE INJURY SUMMARY DATA:'][' PHD --->(Time)'].apply(lambda x : pd.Series(str(x).split('(')))\n","\n","  dict_1['CURVE INJURY SUMMARY DATA:'].drop(['HIC ----->(T1,T2)','HIC_T1_T2','HICD ----->(T1,T2)','HICD_T1_T2',' 3MS ----->(T1,T2)','3MS_T1_T2','THIV --->(Time)',' PHD --->(Time)'], axis=1, inplace =  True)\n","\n","  dict_1['CURVE INJURY SUMMARY DATA:']['HIC_T2'] = dict_1['CURVE INJURY SUMMARY DATA:']['HIC_T2'].apply(lambda x : remove_parenthesis_string(x))\n","  dict_1['CURVE INJURY SUMMARY DATA:']['HICD_T2'] = dict_1['CURVE INJURY SUMMARY DATA:']['HICD_T2'].apply(lambda x : remove_parenthesis_string(x))\n","  dict_1['CURVE INJURY SUMMARY DATA:']['3MS_T2'] = dict_1['CURVE INJURY SUMMARY DATA:']['3MS_T2'].apply(lambda x : remove_parenthesis_string(x))\n","  dict_1['CURVE INJURY SUMMARY DATA:']['THIV_TIME'] = dict_1['CURVE INJURY SUMMARY DATA:']['THIV_TIME'].apply(lambda x : remove_parenthesis_string(x))\n","  dict_1['CURVE INJURY SUMMARY DATA:']['PHD_TIME'] = dict_1['CURVE INJURY SUMMARY DATA:']['PHD_TIME'].apply(lambda x : remove_parenthesis_string(x))\n","  dict_1['CURVE INJURY SUMMARY DATA:'] = dict_1['CURVE INJURY SUMMARY DATA:'].astype(np.float32)\n","#-----------------------------------------------------------------------------"],"metadata":{"id":"4ePrGQu6_aZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------\n","# create log file for all available results in the root folder\n","#-----------------------------------------------------------------------------\n","list_1 = []\n","def get_index(x):\n","  list_1.append(x)\n","  return (list_1.count(x))\n","\n","log_file = pd.DataFrame(columns = ['Model', 'Iteration','PDOF','File_Name', 'File_Path'])\n","models = os.listdir(DATASET_PATH)\n","for i in np.arange(len(models)):\n","  iterations = os.listdir(os.path.join(DATASET_PATH,models[i]))\n","  for j in np.arange(len(iterations)):\n","    if os.path.isdir(os.path.join(DATASET_PATH,models[i],iterations[j])):\n","      PDOF = os.listdir(os.path.join(DATASET_PATH,models[i],iterations[j]))\n","      for p in np.arange(len(PDOF)):\n","        if os.path.isdir(os.path.join(DATASET_PATH,models[i],iterations[j],PDOF[p])):\n","          files = os.listdir(os.path.join(DATASET_PATH,models[i],iterations[j],PDOF[p]))\n","          for s in np.arange(len(files)):\n","            log_file.loc[len(log_file.index)] = [models[i],iterations[j],PDOF[p],files[s], os.path.join(DATASET_PATH,models[i],iterations[j],PDOF[p],files[s])]\n","        else:\n","          log_file.loc[len(log_file.index)] = [models[i],iterations[j],'',PDOF[p],os.path.join(DATASET_PATH,models[i],iterations[j],PDOF[p])]\n","    else :\n","      log_file.loc[len(log_file.index)] = [models[i],'','',iterations[j],os.path.join(DATASET_PATH,models[i],iterations[j])]\n","#-----------------------------------------------------------------------------\n","log_file['z_index'] = log_file['File_Name'].apply(lambda x :  get_index(x))\n","log_file.sort_values(by = 'z_index', inplace = True) \n","log_file.to_csv('/content/drive/MyDrive/Google Documents/UpWork_Task_30_Dec_2021/' + 'log_file.csv', index = False)\n","del i,j,p,s,models, PDOF, files,iterations , list_1\n","#-----------------------------------------------------------------------------"],"metadata":{"id":"S9tjp9x__q7S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unique_files = log_file['File_Name'].unique()\n","#print(\"Total No. of Unique Files :\", len(unique_files))\n","# Initializing Dataframe For SignalValue Files\n","for i in np.arange(len(unique_files)):\n","  if(unique_files[i].split('.')[1] == \"sngval\"):\n","    locals()[unique_files[i].split(\".\")[0] + \"_Block_1\"] = pd.DataFrame()\n","    locals()[unique_files[i].split(\".\")[0] + \"_Block_2\"] = pd.DataFrame()\n","    locals()[unique_files[i].split(\".\")[0] + \"_Block_3\"] = pd.DataFrame()\n","\n","# Initializing Dataframe For CSV Files\n","for file_path_index in np.arange(len(log_file)): \n","  file_name = log_file['File_Name'].iloc[file_path_index].split(\".\")[0]\n","  file_type = log_file['File_Name'].iloc[file_path_index].split(\".\")[1]\n","  model_name = log_file['Model'].iloc[file_path_index]\n","  if(file_type == 'csv'):\n","    locals()[file_name + \"_\" + model_name] = pd.DataFrame()\n","\n","# Reading data from LogFile one by one\n","for file_path_index in np.arange(len(log_file)): \n","  file_name = log_file['File_Name'].iloc[file_path_index].split(\".\")[0]\n","  file_type = log_file['File_Name'].iloc[file_path_index].split(\".\")[1]\n","  model_name = log_file['Model'].iloc[file_path_index]\n","  if(file_type == 'sngval'):\n","    z_index = log_file['z_index'].iloc[file_path_index]\n","    with open(log_file['File_Path'].iloc[file_path_index], 'r',encoding='UTF-8') as file:\n","      file_data = file.readlines()\n","\n","    #Running all Functions\n","    dict_1 =  {}  # Dictionary for storing dataframes\n","    all_data_separated = get_separated_data()  # Get Separated Data\n","    max_length = len(all_data_separated[0][0]) # Get Maximum length of any record in File\n","    get_data_in_dataframe(all_data_separated, max_length) # Put Data in DataFrame\n","    clean_data() # Remove Brackets\n","\n","    dict_1['CURVE BASIC SUMMARY DATA']['z_index'] = z_index\n","    dict_1['CURVE INJURY SUMMARY DATA:']['z_index'] = z_index\n","    dict_1['CURVE LABELS:']['z_index'] = z_index\n","\n","    if(z_index == 1):    \n","      locals()[file_name +\"_Block_1\"] = dict_1['CURVE BASIC SUMMARY DATA']\n","      locals()[file_name +\"_Block_2\"] = dict_1['CURVE INJURY SUMMARY DATA:']\n","      locals()[file_name +\"_Block_3\"] = dict_1['CURVE LABELS:']\n","    else :\n","      locals()[file_name +\"_Block_1\"] = locals()[file_name +\"_Block_1\"].append(dict_1['CURVE BASIC SUMMARY DATA'])\n","      locals()[file_name +\"_Block_2\"] = locals()[file_name +\"_Block_2\"].append(dict_1['CURVE INJURY SUMMARY DATA:'])\n","      locals()[file_name +\"_Block_3\"] = locals()[file_name +\"_Block_3\"].append(dict_1['CURVE LABELS:'])\n","    del all_data_separated, dict_1, file_data, data, file\n","  elif(file_type == 'csv'):\n","    z_index = log_file['z_index'].iloc[file_path_index]\n","    if (z_index ==1):\n","      if((file_name == \"load_cell\") or (file_name == \"ligament_force\") or (file_name == \"foot_kinematics\") or (file_name == \"ligament_stretch\")  ):\n","        locals()[file_name + \"_\" + model_name] = pd.read_csv(log_file['File_Path'].iloc[file_path_index], skiprows=1)\n","        locals()[file_name + \"_\" + model_name] = locals()[file_name + \"_\" + model_name].iloc[:, :-1]\n","        locals()[file_name + \"_\" + model_name]['z_index'] =z_index\n","      else:\n","        locals()[file_name + \"_\" + model_name] = pd.read_csv(log_file['File_Path'].iloc[file_path_index])\n","        locals()[file_name + \"_\" + model_name]['z_index'] =z_index\n","    else :\n","      if(len(locals()[file_name + \"_\" + model_name]) >0):\n","        if((file_name == \"load_cell\") or (file_name == \"ligament_force\") or (file_name == \"foot_kinematics\") or (file_name == \"ligament_stretch\")):\n","          data = pd.read_csv(log_file['File_Path'].iloc[file_path_index], skiprows = 1)\n","          data = data.iloc[:, :-1]\n","        else:\n","          data = pd.read_csv(log_file['File_Path'].iloc[file_path_index])\n","        data['z_index'] = z_index\n","        locals()[file_name + \"_\" + model_name] = locals()[file_name + \"_\" + model_name].append(data)\n","      else:\n","        if((file_name == \"load_cell\") or (file_name == \"ligament_force\") or (file_name == \"foot_kinematics\") or (file_name == \"ligament_stretch\")  ):\n","          locals()[file_name + \"_\" + model_name] = pd.read_csv(log_file['File_Path'].iloc[file_path_index], skiprows=1)\n","          locals()[file_name + \"_\" + model_name] = locals()[file_name + \"_\" + model_name].iloc[:, :-1]\n","          locals()[file_name + \"_\" + model_name]['z_index'] =z_index\n","        else:\n","          locals()[file_name + \"_\" + model_name] = pd.read_csv(log_file['File_Path'].iloc[file_path_index])\n","          locals()[file_name + \"_\" + model_name]['z_index'] =z_index\n","\n","# Removing variables that not required \n","del unique_files, z_index, i, data, file_type, model_name, file_name, file_path_index\n","\n","# Creating Multidimention Z Index\n","for var in dir():\n","  if(isinstance(eval(var),pd.core.frame.DataFrame)):\n","    if(var !=\"log_file\"):\n","      locals()[var].reset_index(drop=False, inplace = True)\n","      locals()[var].set_index(['z_index', 'index'], inplace=True)\n","\n","# Removing variables that not required \n","del var"],"metadata":{"id":"sSWSwN5z_zZX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------- Starts From Here-----------------------------------------------------------------"],"metadata":{"id":"3Dgqa58-NlkN"}},{"cell_type":"code","source":["#------------Enter data to filter-----------------------------------------------------------------\n","z_model = ['GHBMC_5F']\n","z_iteration = ['i1', 'i2']\n","z_pdof = ['FF','FS']\n","#-----------------------------------------------------------------------------------------------\n","z_log = log_file[log_file['Model'].isin(z_model)]\n","z_log = z_log[z_log['Iteration'].isin(z_iteration)]\n","z_log = z_log[z_log['PDOF'].isin(z_pdof)]\n","z_files = z_log['File_Name'].unique()\n","z_index = z_log['z_index'].unique()\n","z_log['z_path'] = z_log['Model'] + \"_\" + z_log['Iteration'] + \"_\" + z_log['PDOF']"],"metadata":{"id":"04DJKPFMLyvH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting Filtered data ready for plotting\n","temp_df_1 = locals()['load_cell_' + z_model[0]].copy()\n","temp_df_1.reset_index(drop= False, inplace = True)\n","temp_df_1 = temp_df_1[temp_df_1['z_index'].isin(z_index)]\n","temp_dict = dict(zip(z_log['z_index'],z_log['z_path']))\n","temp_df_1['z_path'] = temp_df_1['z_index'].map(temp_dict)\n","\n","temp_df_2 = locals()['foot_kinematics_' + z_model[0]].copy()\n","temp_df_2.reset_index(drop= False, inplace = True)\n","temp_df_2 = temp_df_2[temp_df_2['z_index'].isin(z_index)]\n","temp_df_2['z_path'] = temp_df_2['z_index'].map(temp_dict)\n","del z_log,z_iteration,z_pdof,z_files , z_index , temp_dict"],"metadata":{"id":"aAeSQOI4N4BH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Defining Axis Labels , titles , column names\n","load_cell_columns = list(locals()['load_cell_'+z_model[0]+ '_results'].columns)\n","foot_kiematics_columns = list(locals()['foot_kinematics_'+z_model[0]+'_results'].columns)\n","load_cell_title = [\"Distal tibia-febula resultant force\",\"Distal tibia-febula x force\",\"Inversion(+) Eversion (-)\",\"Distal tibia-febula y force\",\"Dorsiflexion(+) Plantarflexion(-)\",\n","                   \"Distal tibia-febula z force\",\"Moment z\"]\n","foot_kinematics_title = [\"Inversion(+) Eversion (-)\",\"Inversion(+) Eversion (-)\",\"Inversion(+) Eversion (-)\",\"Dorsiflexion(+) Plantarflexion(-)\",\"Dorsiflexion(+) Plantarflexion(-)\",\n","                         \"Dorsiflexion(+) Plantarflexion(-)\" ]\n","load_cell_y_label = [\"Force (kN)\",\"Force (kN)\",\"Moment (Nm)\",\"Force (kN)\",\"Moment (Nm)\",\"Force (kN)\",\"Moment (Nm)\"]\n","foot_kinametic_y_label = ['Angular acceleration (degrees/ms2)','Angular rotation (degrees)','Angular velocity (degrees/ms)','Angular acceleration (degrees/ms2)','Angular rotation (degrees)',\n","                          'Angular velocity (degrees/ms)']\n","\n","# Functions for Plotly Chart\n","def load_cell_chart(y_column,y_label, _title):\n","  fig = px.line(x = temp_df_1['Time'],y = temp_df_1[y_column], color =temp_df_1['z_path'],\n","              labels=dict(x=\"Time\", y=y_label, color =\"Path\"))\n","  fig.update_layout(title = _title, title_x = 0.5)\n","  fig.show()\n","\n","def foot_kinametic_chart(y_column,y_label, _title):\n","  fig = px.line(x = temp_df_2['Time'],y = temp_df_2[y_column], color =temp_df_2['z_path'],\n","              labels=dict(x=\"Time\", y=y_label, color =\"path\"))\n","  fig.update_layout(title = _title, title_x = 0.5)\n","  fig.show()"],"metadata":{"id":"uXsPukxF-5r4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Coefficient Correlation Filtering Chart"],"metadata":{"id":"ja3yzRYyF5b1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Enter data for filtering\n","# Put min or max in small letters\n","#--------------------Enter Filtered Detailed here-----------------------------\n","model = [\"GHBMC_5F\"]\n","iteration = ['i1', 'i2','i3']\n","pdof = ['FF','FS']\n","\n","load_cell_cols = list(locals()['load_cell_'+model[0]+ '_results'].columns)\n","foot_kiematics_cols = list(locals()['foot_kinematics_'+model[0]+'_results'].columns)\n","\n","var_1 = [load_cell_cols[2],'max',foot_kiematics_cols[3],'min'] \n","var_2 = ['ligament_estrain','max']\n","\n","#------------------------##-----------------------------##--------------------\n","\n","log_data = log_file[log_file['Model'].isin(model)]\n","log_data = log_data[log_data['Iteration'].isin(iteration)]\n","log_data = log_data[log_data['PDOF'].isin(pdof)]\n","unique_files = log_data['File_Name'].unique()\n","unique_z_index = log_data['z_index'].unique()\n","log_data['z_path'] = log_data['Model'] + \"_\" + log_data['Iteration'] + \"_\" + log_data['PDOF']"],"metadata":{"id":"eq4VV3XEGlRi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["variable_selected = []\n","combine_data = pd.DataFrame()\n","temp_df_var_2 = locals()[var_2[0] +'_' + model[0] + '_results'].reset_index()\n","temp_df_var_2 = temp_df_var_2[temp_df_var_2['z_index'].isin(unique_z_index)]\n","temp_df_var_2 = temp_df_var_2[temp_df_var_2['index'] == var_2[1]]\n","temp_df_var_2.drop(labels = ['index', 'z_index'], axis=1, inplace=True)\n","temp_df_var_2.reset_index(drop= True, inplace= True)\n","\n","for i in np.arange(len(var_1)):\n","  if((i%2) == 0):\n","    variable_selected.append(var_1[i])\n","    if (var_1[i] in (locals()['load_cell_'+model[0]+'_results'].columns)): # Looking for column in load cell\n","      temp_df_var_1 = locals()['load_cell_'+model[0]+'_results'].reset_index()\n","      temp_df_var_1 = temp_df_var_1[temp_df_var_1['z_index'].isin(unique_z_index)]\n","      temp_df_var_1 = temp_df_var_1[['index',var_1[i]]]\n","      temp_df_var_1 = temp_df_var_1[temp_df_var_1['index'] == var_1[i+1]]\n","      temp_df_var_1.drop('index', axis=1, inplace=True)\n","      temp_df_var_1.reset_index(drop= True, inplace = True)\n","      combine_data[var_1[i]] = temp_df_var_1[var_1[i]]\n","      combine_data.reset_index(drop=True, inplace =True)\n","    elif(var_1[i] in (locals()['foot_kinematics_'+model[0]+'_results'].columns)): # Looking for columnn in foot_kiematics\n","      temp_df_var_1 = locals()['foot_kinematics_'+model[0]+'_results'].reset_index()\n","      temp_df_var_1 = temp_df_var_1[temp_df_var_1['z_index'].isin(unique_z_index)]\n","      temp_df_var_1 = temp_df_var_1[['index',var_1[i]]]\n","      temp_df_var_1 = temp_df_var_1[temp_df_var_1['index'] == var_1[i+1]]\n","      temp_df_var_1.drop('index', axis=1, inplace=True)\n","      temp_df_var_1.reset_index(drop= True, inplace = True)\n","      combine_data[var_1[i]] = temp_df_var_1[var_1[i]]\n","      combine_data.reset_index(drop=True, inplace =True)\n","    else:\n","      print(\"Column Name not found :\",var_1[i])"],"metadata":{"id":"x19nneFPIcfx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["correlated_df = pd.DataFrame(columns = temp_df_var_2.columns, index =variable_selected)\n","for j in np.arange(len(variable_selected)):\n","  for i in np.arange(len(temp_df_var_2.columns)):\n","    col_1 = temp_df_var_2[temp_df_var_2.columns[i]].astype(float)\n","    col_2 = combine_data[variable_selected[j]].astype(float)\n","    correlated_df.iloc[j][correlated_df.columns[i]] = col_1.corr(col_2)"],"metadata":{"id":"c__JXRUvIeMy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = correlated_df.T.plot(figsize = (25,8), kind ='bar')\n","plt.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n","plt.ylim(-1,1)\n","for p in x.patches:\n","  if(p.get_height()> 0):\n","    x.annotate(round(p.get_height(),2), (p.get_x() * 1.005, p.get_height() + 0.05),rotation=90)\n","  else:\n","    x.annotate(round(p.get_height(),2), (p.get_x() * 1.005, p.get_height() -0.10),rotation=90)\n","plt.show()"],"metadata":{"id":"GDZ106yKLSpd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp_df_3 = locals()[var_2[0] +'_' + model[0] + '_results'].copy()\n","temp_df_3 = temp_df_3.reset_index(drop= False)\n","temp_df_3 = temp_df_3[temp_df_3['z_index'].isin(unique_z_index)]\n","temp_df_3 = temp_df_3[temp_df_3['index'] == var_2[1]]\n","temp_dict =     dict(zip(log_data['z_index'],log_data['z_path']))\n","temp_df_3['z_path'] = temp_df_3['z_index'].map(temp_dict)\n","temp_df_3.drop(labels = ['index','z_index'], axis=1, inplace=True)\n","temp_df_3.set_index('z_path', inplace = True)\n","temp_df_3.T.plot(figsize = (25,8), kind ='bar')\n","plt.legend(loc='best')\n","plt.show()"],"metadata":{"id":"KZtA5NzveoKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"0TDMnsU6CQU7"},"execution_count":null,"outputs":[]}]}